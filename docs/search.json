[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary CASA0023",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "9  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#about-the-book",
    "href": "index.html#about-the-book",
    "title": "Learning Diary CASA0023",
    "section": "About the book",
    "text": "About the book\nThis book summarises my thoughts and reflections on the CASA0023 ‘Remote Sensing Cities and the Environment’ course. I took the course as part of my MSc in Urban Spatial Science at University College London. I look forward to receiving your valuable comments on this book."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Learning Diary CASA0023",
    "section": "About me",
    "text": "About me\nHello, my name is Zhiwei Huang or Morgan, and I am from Inner Mongolia Autonomous Region, a wonderful place in China. I graduated from Zhejiang University with a Bachelor’s degree in Urban and Rural Planning, and during my undergraduate studies, my main research area was quantitative research on transport development. My current research interests are focused on two aspects: on the one hand, how to introduce more precise and intelligent research methods in urban research, and on the other hand, focusing on the development differences between cities and urban-rural areas to explore the regional and modal differences in spatial development.\n\n\n\n\n\n\n\n\n\nContact details\nMail: zhiwei.huang.22@ucl.ac.uk / huangzhiwei_hz@163.com\nPhone numbers: +86 15004921091"
  },
  {
    "objectID": "index.html#instructions",
    "href": "index.html#instructions",
    "title": "Learning Diary CASA0023",
    "section": "Instructions",
    "text": "Instructions\nSpecial thanks to Dr Andy MacLachlan for his help in the preparation of this book."
  },
  {
    "objectID": "index.html#instruction",
    "href": "index.html#instruction",
    "title": "Learning Diary CASA0023",
    "section": "Instruction",
    "text": "Instruction\nSpecial thanks to Dr Andy MacLachlan for his help in the preparation of this book."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Remotely Sensors: TerraSAR-X and TanDEM-X",
    "section": "",
    "text": "3 Features, applications and reflections of the sensors.\nhttps://111vdfsvds.github.io/CASA23_Zhiwei/#1"
  },
  {
    "objectID": "week2.html#features-applications-and-reflections-of-the-sensors.",
    "href": "week2.html#features-applications-and-reflections-of-the-sensors.",
    "title": "2  Sensors: TerraSAR-X and TanDEM-X",
    "section": "2.1 Features, applications and reflections of the sensors.",
    "text": "2.1 Features, applications and reflections of the sensors.\nA basic introduction on WorldView-3"
  },
  {
    "objectID": "week2.html#features-applications-and-reflections",
    "href": "week2.html#features-applications-and-reflections",
    "title": "2  Sensors: TerraSAR-X and TanDEM-X",
    "section": "2.1 Features, applications and reflections",
    "text": "2.1 Features, applications and reflections\nA basic introduction on TerraSAR-X and TanDEM-X"
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  week1:",
    "section": "",
    "text": "2 Introduction to Remote Sensing\nIn this week’s lesson, we first learned what remote sensing is, what it is helpful for, and what classifying features remote sensing data has. Landsat and Sentinel were then studied and analysed, including a tasselled-cap transformation method. Finally, by consulting the references, we consider the fields in which remote sensing data are widely used."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arapoglou, Vassilis P. 2012. “Diversity, Inequality and Urban\nChange.” European Urban and Regional Studies 19 (3):\n223–37. https://doi.org/10.1177/0969776412451800."
  },
  {
    "objectID": "week1.html#what-is-remote-sensing",
    "href": "week1.html#what-is-remote-sensing",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 What Is Remote Sensing",
    "text": "1.1 What Is Remote Sensing\nRemote sensing is the observation of the Earth from a distance using remote sensors on satellites or aircraft. Remote sensing provides a wealth of global perspectives and geographic information data(Earth Science Data Systems 2019).\nRemote sensing can be categorised according to the following elements.\n\n1.1.1 Earth Orbits\nThere are three types of Earth orbits: high Earth orbit, medium Earth orbit, and low Earth orbit. Many weathers and some communication satellites tend to have high Earth orbits farthest from the surface(“Catalog of Earth Satellite Orbits” 2009). Satellites operating in medium (medium) Earth orbit include navigation satellites and specialised satellites designed to monitor specific areas.\n\n\n\n\n\nOne way of classifying orbits is by altitude. Source: earthobservatory.nasa\n\n\n\n\nThe altitude of the orbit, or the distance between the satellite and the Earth’s surface, determines how fast the satellite moves around the Earth. As satellites get closer to Earth, the pull of gravity becomes more muscular, and satellites move faster.\n\n\n1.1.2 Electromagnetic Spectrum\nThe electromagnetic spectrum ranges from shorter wavelengths to longer wavelengths. In most cases, the ultraviolet or ultraviolet portion of the spectrum has the shortest wavelength, which is helpful for remote sensing, and this radiation exceeds the violet part of the visible wavelength. Some earth’s surface materials, mainly rocks and minerals, fluoresce or emit visible light when exposed to ultraviolet light.\n\n\n\n\n\nDiagram of the Electromagnetic Spectrum. Source: earthobservatory.nasa\n\n\n\n\nThe light that our eyes can detect is part of the visible spectrum. Much radiation around us is “invisible” to our eyes but can be seen by other remote sensing instruments and used in our research.\n\n\n1.1.3 Resolution\nResolution plays a vital role in how the data from the sensor is used. Resolution can vary depending on the satellite’s orbit and sensor design, and for any dataset, there are four types of resolution to consider: radiation, space, spectrum, and time.\n\nRadiation resolution is the sensitivity of a remote sensing platform to detect subtle differences in energy.\nSpatial resolution measures the minimum angular spacing between two objects.\nThe spectral resolution is the number and size of bands in the electromagnetic spectrum that a remote sensing platform can capture.\nTemporal resolution refers to how often imagery is recorded for a particular area.\n\n\n\n1.1.4 Sensors\nAccording to the signal source of the exploration object, sensors can be divided into two types: active and passive. Active remote sensing instruments use their own emission sources, while passive remote sensing instruments operate on reflective or light sources.\nEach active sensor in remote sensing directs its signal to an object, then examines the response and accepts the data. Most devices use microwaves because they are relatively unaffected by weather conditions.\n\n\n\n\n\nDiagram of a passive sensor versus an active sensor. Source: earthobservatory.nasa\n\n\n\n\nUnlike active sensors, passive sensors do not streamline their energy to the object or surface being studied. Passive remote sensing relies on the natural energy (sunlight) reflected by the target. Therefore, it should only be used in proper sunlight. Otherwise, there will be nothing to remember."
  },
  {
    "objectID": "week1.html#remotely-data-and-processing-methods",
    "href": "week1.html#remotely-data-and-processing-methods",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Remotely Data and Processing Methods",
    "text": "1.2 Remotely Data and Processing Methods\n\n1.2.1 Landsat Data and Sentinel Data\nLandsat and Sentinel sensors provide medium to high spatial resolution multispectral data for various applications. Through the synergistic use of Landsat and Sentinel data, it is expected to improve timely and accurate observations of the Earth’s surface and dynamics.\nLandsat is a scientific Earth observation mission of NASA and the U.S. Geological Survey (USGS) that regularly captures images of the globe. Since its first launch in 1972, Landsat has collected data on forests, farmland, urban areas and freshwater, producing the longest continuous record of its kind. The Sentinel satellite is a European Space Agency (ESA) satellite designed to provide a large amount of data and images for Europe’s Copernicus program. Sentinel-1 has bipolar orbiting satellites to provide spatial data for environmental and security assurances and global economic and commercial growth.\n\n\n1.2.2 Processing Methods\nStandard processing methods for remote sensing data include the following:\nThe Tasseled-Cap transformation method converts remote sensing image data into three principal components to better describe the land cover type. The three main components are “brightness”, “greenness”, and “humidity”, which can be used to identify land use types and monitor vegetation growth status.\nThe Normalized Vegetation Index is a widely used index to measure vegetation cover. NDVI calculations are based on the ratio between infrared and visible bands and can be used to monitor vegetation growth, estimate vegetation productivity, and more.\nPrincipal Component Analysis (PCA): This method converts multiband remote sensing data into several principal components to characterise the land cover type better. This method can classify and monitor land use change, vegetation growth, etc.\n\n\n1.2.3 Applications\n\n\n1.2.4 Agriculture and Forestry\nIt can monitor vegetation cover, land-use change, drought and disasters, etc., to help crop production and forest management. Time series from the Landsat and Sentinel-2 satellites have great potential for simulating vegetation seasonality(Jönsson et al. 2018).\n\n\n1.2.5 Water Management\nIt can monitor changes in water bodies, including water level, flow rate, water temperature, etc., which helps in water management and protection. Using multi-sensor data such as Landsat 7 ETM+, Landsat 8 OLI and Sentinel-1 SAR images as source data, a regional adaptive random forest algorithm can be constructed to realise automatic surface water mapping(Tang et al. 2022)."
  },
  {
    "objectID": "week1.html#reflaction",
    "href": "week1.html#reflaction",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflaction",
    "text": "1.3 Reflaction\nThrough the above, we can understand the meaning and categories of remote sensing, the processing methods of remote sensing data, and the current related research fields. I believe that remote sensing data has potential development in the following areas.\n\n1.3.1 Remote Sensing Data Optimisation Based on Machine Learning\nRemote sensing data are subject to interference from various factors, such as atmospheric disturbance, cloud cover, etc., which may affect the quality and reliability of the data. In the future, multiple technologies, such as machine learning algorithms, can be employed to improve the quality and reliability of data.\n\n\n1.3.2 Real-time Information Detection Platform\nBased on remote sensing data, current affairs feedback the city. Urban planning is dynamic, and urban surface information needs constantly change. Therefore, it is necessary to establish a complete urban surface information monitoring system and a regular feedback mechanism to meet urban planning needs.\n\n\n1.3.3 Multi-source Data Integration\nUrban surface information involves multiple aspects, such as terrain, buildings, traffic, vegetation, etc., so multi-source data integration is required. Different data sources have other data formats and resolutions, and effectively integrating this data is challenging. In the future, more data fusion techniques can be adopted.\n\n\n\n\n“Catalog of Earth Satellite Orbits.” 2009. https://earthobservatory.nasa.gov/features/OrbitsCatalog.\n\n\nEarth Science Data Systems, NASA. 2019. “What Is Remote Sensing?” https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing.\n\n\nJönsson, Per, Zhanzhang Cai, Eli Melaas, Mark A. Friedl, and Lars Eklundh. 2018. “A Method for Robust Estimation of Vegetation Seasonality from Landsat and Sentinel-2 Time Series Data.” Remote Sensing 10 (4): 635. https://doi.org/10.3390/rs10040635.\n\n\nTang, Hailong, Shanlong Lu, Muhammad Hasan Ali Baig, Mingyang Li, Chun Fang, and Yong Wang. 2022. “Large-Scale Surface Water Mapping Based on Landsat and Sentinel-1 Images.” Water 14 (9): 1454. https://doi.org/10.3390/w14091454."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Pyramid Scaling",
    "section": "",
    "text": "How does it work?\nAnalysis is divided between a client side - the Earth Engine browser interface - and the server side, where the data is stored and the processing is performed.\nDue to the huge volume of data that can be involved in Earth Engine calculations and visualisations, the system also uses different methods to reduce data load/computing time:\n\nLazy ComputationDistributed Computing\n\n\n‘Lazy’ computation refers to the process of only computing the data that are necessary, such as that in the user’s current view (if using an interactive display). The window’s zoom level and bounds will dynamically control the projection and resolution of the computed data.\n\n\nThe Earth Engine code library provides a suite of inbuilt functions that are designed to maximise performance on the cloud-based computing system. Methods such as parallelisation and distributed computing break down larger jobs to be run across many smaller machines, allowing faster times to produce client output.\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\nExamples\n\n\n\n\nGeometric Correction (includes Orthorectification, or Topographic Correction) *CHECK THIS\nAccounts for differences in sensor view angles. Corrections will use methods such as ground control points, where known points are identified in both images. See figure below.\nMaking the images taken straight down (“nadir”) comparable to images from off-centre (“off-nadir”)\n\n\nAtmospheric Correction\nAccounts for the ‘haze’ caused by atmospheric scattering and absorption.\nUsing Dark Object Subtraction (DOS) to quantify the difference between surface reflectance and top-of-atmosphere (TOA) reflectance.\n\n\nResampling\nAccounts for difference in spatial resolution of raster images. Resampling is used to calculate values for ‘lower’ resolution pixels calculated from the component higher resolution pixels.\nUsed to resample Landsat bands taken at 10m resolution into lower resolution 20m pixels, to allow band math with other bands recorded at 20m resolution. [SPECIFY THE BANDS AT 20; FROM PRAC 1]\n\n\nRadiometric Calibration\nAccounts for the conversion of unitless data collected by the sensor (a ‘Digital Number’) to a value indicating the spectral radiance.\nThe transition from Digital Number to Radiance to Reflectance represents different values corresponding to increasing levels of correction/processing.\n\n\nPoint Spread Functions\nAccounts for the spread of reflectance values that contribute to a single pixel. The centre of a pixel will have the greatest influence on the observed reflectance; point spread functions calculate the influence of pixel sections as distance increases from the centre."
  },
  {
    "objectID": "week3.html#about-the-corrections",
    "href": "week3.html#about-the-corrections",
    "title": "3  Corrections",
    "section": "3.1 About the corrections",
    "text": "3.1 About the corrections\n\n3.1.1 Pre-processing requirements\nThe remote sensing data acquisition process is affected by several factors that can degrade the quality of the acquired images. This may affect the accuracy of image analysis. The purpose of image correction and restoration is to correct distorted and degraded image data to create a more faithful representation of the original scene. This step is often called preprocessing because it typically extracts information from the image for a specific application before the actual image analysis.\nA common barrier to using remotely sensed data for nature conservation is the difficulty of obtaining or generating pre-processed data to meet a standard of confidence in its subsequent use. This processing is essential to facilitate physical measurements (e.g., temperature, surface reflectance, altitude) and to compare data obtained from different dates or regions (e.g., reflectance or radar backscatter). For optical and radar data, this preprocessing includes atmospheric and topographic correction, orthorectification, and more, and for lidar, ground echo classification and surface height retrieval\n\n\n3.1.2 Geometric corrections\n\n3.1.2.1 Why do geometric corrections are needed?\nAll remotely sensed images of the Earth’s surface contain many geometric distortions. Distortion is inherent in the acquisition geometry, whether acquired by a multispectral scanner on a satellite, a photographic system on an aircraft, or any other platform/sensor combination, with various geometric distortions. This problem is inherent in remote sensing. These errors can be due to a variety of factors, including one or more of the following(Canada 2008):\n\nViewing angle of sensor optics\nThe movement of the scanning system\nMovement and (in)stability of the platform\nPlatform height, attitude and speed\nThe terrain is undulating\nThe curvature and rotation of the Earth\n\nThe sources of geometric distortion and positional errors vary from case to case but are inherent in remote sensing imagery. In most cases, we can eliminate or at least reduce these errors, but they must be considered in each case before attempting to make a measurement or extract more information.\n\n\n3.1.2.2 The methods of geometric corrections\nGeometric corrections are achieved in the following four steps:\n\nGet Ground Control Points (GCPs).\nBuild sensor models\nCoordinate transformation\n\n\n\n\n\n\nCoordinate Transformation. Source: Wiki\n\n\n\n\n\nResampling of pixel values\n\n\n\n\n\n\nNearest Neighbor Resampling. Source: Wiki\n\n\n\n\n\n\n\n3.1.3 Atmospheric corrections\nThe solar radiation reflected from the Earth’s surface to satellite sensors is altered by its interaction with the atmosphere. Atmospheric correction aims to determine the true surface reflectance value (.) by eliminating atmospheric effects in satellite imagery.\n\n\n\n\n\nAtmospheric Effect on Remote Sensing Data. Source: Slide Share\n\n\n\n\nThe atmospheric effects in optical remote sensing are significant and complex, dramatically altering the spectral properties of the radiation reaching the remote sensor. The atmosphere absorbs and scatters various wavelengths of the visible spectrum that must pass through the atmosphere twice, once from the sun to the object and then propagate again when it returns to the image sensor. These distortions are corrected using a variety of methods and techniques.\n\n\n\n\n\nExample of Atmospheric Correction a Landsat Image With Haze Effect Before Correction. Source: ResearchGate\n\n\n\n\n\n\n3.1.4 Orthorectification correction\n\n3.1.4.1 What is Orthorectification correction？\nThe original satellite imagery contains distortion caused by sensor orientation, terrain changes, and Earth’s curvature. When collecting satellite imagery, it needs to be processed using orthorectification to correct for inaccuracies.\nDistortion occurs in feature displacement and causes scaling inconsistencies in the image. The distortion level changes throughout the imagery scene, meaning simple ground control point adjustments alone cannot compensate for these errors. The correction process for terrain changes and sensor orientation needs to be considered to rearrange displaced pixels to the correct position.\n\n\n\n\n\nOrthorectification Correction. Source: InterMap\n\n\n\n\n\n\n3.1.4.2 Accurate elevation models are key\nFeature distortion on the original imagery is greatly affected by terrain changes. An accurate elevation model is required to calculate the effect of terrain changes on imagery pixels. This calculation can then pinpoint the pixel to the correct location.\n\n\n\n\n\nOrtho Image. Source: InterMap\n\n\n\n\n\n\n\n3.1.5 Radiometric correction\nRadiation calibration is crucial for converting raw digital image data from satellite or aerial sensors to a standard physical scale based on known reflectance measurements obtained from ground objects. This type of correction is essential for reliable quantitative measures of images.\nImagery typically begins with an uncalibrated raw number (DN) of the pixel values in the imagery. These DN values are converted to radiance through a series of gains and offsets provided by the app data provider. The degree of radioactivity depends on the illumination (intensity and direction), the law and location of the target feature to be imaged, and the path of light through the atmosphere."
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  Corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\n\n3.2.1 Use machine learning to compare the accuracy of various atmospheric correction methods\nAtmospheric correction is one of the critical parts of remote sensing preprocessing, as it can influence and alter the final classification results. Sentinel-2 satellite imagery was used to study the effects of five different atmospheric correction treatments on land cover classification accuracy. These are Surface Reflectance (SREF), Standardized Surface Reflectance (STDSREF), Sentinel-2 Atmospheric Correction (S2AC), Atmospheric Effects Image Correction (iCOR), Dark Object Subtraction (DOS), and Atmospheric Top (TOA) Reflectivity without any atmospheric correction(Rumora, Miler, and Medak 2020).\n\n\n\n\n\nThe workflow of processing Sentinel-2. Source: MDPI\n\n\n\n\nSentinel-2 images using atmosphere correction are classified using four machine learning techniques(Rumora, Miler, and Medak 2020). SVM classification provides the best overall results for all atmospheric disciplines.\n\n\n\n\n\nClassification maps for four classification techniques and six atmospheric corrections. Source: MDPI\n\n\n\n\n\n\n3.2.2 Atmospheric correction of satellite remote sensing data for agricultural use\nFor agricultural applications, multiple vegetation indices are applied for monitoring using multi-temporal imagery. Combining vegetation indices from remote sensing imagery with other hydrometeorological data, it widely monitors natural disasters such as droughts. The most important task is to retrieve the actual value of the state of vegetation from satellite remote sensing data.\nTen Landsat TM/ETM+ images were used to test the effects of applying an atmospheric correction to retrieve accurate vegetation index and evapotranspiration(Hadjimitsis et al. 2010). It was found that the calculation of the DVI, NDVI, SAVI and MSAVI indices should consider the influence of the atmosphere. Only SARVI was found unaffected by the atmosphere. Effects of the atmosphere. The results of the atmosphere are variable, and the impact on crops is significant."
  },
  {
    "objectID": "week3.html#reflaction",
    "href": "week3.html#reflaction",
    "title": "3  Corrections",
    "section": "3.3 Reflaction",
    "text": "3.3 Reflaction\nThe application value of the correction method in urban planning is mainly reflected in improving the availability and credibility of remote sensing images to provide a more accurate, detailed and dynamic information source for urban planning. For example, atmospheric correction can eliminate the influence of atmospheric scattering and absorption on image reflectivity, thereby improving the accuracy of feature classification and identification; Orthorectification correction enhances the accuracy of image positioning and measurement by eliminating the effects of terrain undulation and sensor tilt on geometric image distortion.\nChoose the right method In future research, it is necessary to carefully select appropriate correction methods and parameters to adapt to different types, resolutions, and temporal and spatial ranges of remote sensing images and other goals, needs and standards of urban planning tasks. Moreover, the data processing process and technical means of the correction method are essential, which can improve the data processing efficiency, reduce the cost of data processing, and enhance the visualisation of data processing.\nCombined with other types of data How to combine other data sources and technical means (such as ground observation, GIS, artificial intelligence, etc.) to make up for the limitations and shortcomings of the correction method and expand the application scope and depth of the correction method in urban planning.\n\n\n\n\nCanada, Natural Resources. 2008. “Geometric Distortion in Imagery.” https://natural-resources.canada.ca/maps-tools-and-publications/satellite-imagery-and-air-photos/tutorial-fundamentals-remote-sensing/satellites-and-sensors/geometric-distortion-imagery/9401.\n\n\nHadjimitsis, D. G., G. Papadavid, A. Agapiou, K. Themistocleous, M. G. Hadjimitsis, A. Retalis, S. Michaelides, N. Chrysoulakis, L. Toulios, and C. R. I. Clayton. 2010. “Atmospheric Correction for Satellite Remotely Sensed Data Intended for Agricultural Applications: Impact on Vegetation Indices.” Natural Hazards and Earth System Sciences 10 (1): 89–95. https://doi.org/10.5194/nhess-10-89-2010.\n\n\nRumora, Luka, Mario Miler, and Damir Medak. 2020. “Impact of Various Atmospheric Corrections on Sentinel-2 Land Cover Classification Accuracy Using Machine Learning Classifiers.” ISPRS International Journal of Geo-Information 9 (4): 277. https://doi.org/10.3390/ijgi9040277."
  }
]